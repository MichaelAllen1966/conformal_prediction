{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal prediction for binary classification\n",
    "\n",
    "Here we show how a binary classifier can be applied to produce one of four classifications:\n",
    "\n",
    "- *Positive*: The instance reaches the threshold for the positive class, but not the negative class.\n",
    "\n",
    "- *Negative*: The instance reaches the threshold for the negative class, but not the positive class.\n",
    "\n",
    "- *Both*: The instance reaches the threshold for both positive and negative classes.\n",
    "\n",
    "- *None*: The instance does not reach the threshold for either class.\n",
    "\n",
    "Adjusting $\\alpha$ (*coverage*) will adjust the balance of classes. A high $\\alpha$ is more likely to classify na instance in both classes, whereas a low $\\alpha$ is more likely to fail to classify in either class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mapie.classification import MapieClassifier\n",
    "from mapie.metrics import classification_coverage_score\n",
    "from mapie.metrics import classification_mean_width_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data\n",
    "\n",
    "Example data will be produced using SK-Learn's `make_blobs` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "# Make train and test data using sklearn's make_classification\n",
    "X, y = make_classification(n_samples=10000, n_classes=2, n_features=5,\n",
    "                           n_informative=5, n_redundant=0, n_clusters_per_class=1,\n",
    "                           class_sep=0.7, random_state=42)\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and MAPIE classifier\n",
    "\n",
    "MAPIE wraps around any model. It fits the model and gets the prediction sets.\n",
    "\n",
    "The `score` method is the same as used above. This method may be used with k-fold MAPIE fitting which fits a model and then gives us prediction sets across the whole test set by using k-fold calibration/test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier\n",
    "classifier = LogisticRegression(random_state=42)\n",
    "mapie_score = MapieClassifier(estimator=classifier, method='score', cv=5)\n",
    "# Fit classifier and get predictions\n",
    "mapie_score.fit(X_train, y_train)\n",
    "y_pred, y_set = mapie_score.predict(X_test, alpha=0.05)\n",
    "# Remove redundant dimension (used if more than one alpha is used)\n",
    "y_set = np.squeeze(y_set)\n",
    "# Show first 5 instances\n",
    "print(y_set[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full coverage\n",
    "cov = classification_coverage_score(y_test, y_set)\n",
    "setsize = classification_mean_width_score(y_set)\n",
    "print(f'Coverage: {cov:0.2f}')\n",
    "print(f'Avg. set size: {setsize:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class-wise performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_wise_performance(y_new, y_set, n_classes):\n",
    "    df = pd.DataFrame()\n",
    "    # Loop through the classes\n",
    "    for i in range(n_classes):\n",
    "    # Calculate the coverage and set size for the current class\n",
    "        ynew = y_new[y_new == i]\n",
    "        yscore = y_set[y_new == i]\n",
    "        cov = classification_coverage_score(ynew, yscore)\n",
    "        size = classification_mean_width_score(yscore)\n",
    "        # Create a new dataframe with the calculated values\n",
    "        temp_df = pd.DataFrame({\n",
    "            \"class\": [i],\n",
    "            \"coverage\": [cov],\n",
    "            \"avg. set size\": [size]\n",
    "            }, index = [i])\n",
    "        # Concatenate the new dataframe with the existing one\n",
    "        df = pd.concat([df, temp_df])\n",
    "    df.set_index('class', inplace=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class-wise performance\n",
    "print('Class wise performance')\n",
    "print(class_wise_performance(y_test, y_set, n_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count how many instances are in the following classes:\n",
    "\n",
    "- *Positive*: The instance reaches the threshold for the positive class, but not the negative class.\n",
    "\n",
    "- *Negative*: The instance reaches the threshold for the negative class, but not the positive class.\n",
    "\n",
    "- *Both*: The instance reaches the threshold for both positive and negative classes.\n",
    "\n",
    "- *None*: The instance does not reach the threshold for either class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_classification(row):\n",
    "    if (row[0] == False) & (row[1] == True):\n",
    "        return 'Positive'    \n",
    "    elif (row[0] == True) & (row[1] == False):\n",
    "        return 'Negative'\n",
    "    elif (row[0] == True) & (row[1] == True):\n",
    "        return 'Both'\n",
    "    else:\n",
    "        return 'None'\n",
    "\n",
    "# Map count_classification function to each row in y_set\n",
    "results = pd.DataFrame(y_set)\n",
    "results['observed'] = y_test\n",
    "results['class'] = results.apply(count_classification, axis=1)\n",
    "# Show first 5 instances\n",
    "print(results[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of instances in each 'count'\n",
    "results['class'].value_counts()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
